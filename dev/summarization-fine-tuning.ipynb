{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-23T20:08:05.238072Z",
     "start_time": "2024-04-23T20:08:03.744603Z"
    }
   },
   "source": [
    "from app.models import Session, Headline, Article, Agency\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt, timedelta as td\n",
    "\n",
    "with Session() as s:\n",
    "    data = s.query(Headline.processed, Headline.first_accessed, Article.url, Agency.name, Agency._bias)\\\n",
    "        .join(Headline.article).join(Article.agency)\\\n",
    "        .filter(Headline.first_accessed > dt.now() - td(hours=12)).all()\n",
    "df = pd.DataFrame(data, columns=['title', 'date', 'url', 'agency', 'bias'])\n",
    "df.head()"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T20:08:05.247457Z",
     "start_time": "2024-04-23T20:08:05.239077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create separate dataframes for each individual day\n",
    "dfs = [group for _, group in df.groupby(df['date'].dt.date)]\n",
    "dfs[0].head()"
   ],
   "id": "c8ce02469755acce",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "from app.analysis.clustering import label_clusters, form_clusters, prepare_cosine\n",
    "\n",
    "for df in dfs:\n",
    "    print(\"Processing\", df['date'].iloc[0])\n",
    "    df = label_clusters(df, form_clusters(prepare_cosine(df['title']), threshold=0.5, min_samples=5))\n",
    "    # merge all headlines in the same cluster\n",
    "    date = df['date'].iloc[0]\n",
    "    df = df[['title', 'cluster']]\n",
    "    df = df.groupby('cluster').agg({'title': ' '.join}).reset_index()\n",
    "    df.to_csv(date.strftime('%Y-%m-%d.csv'), index=False)\n",
    "dfs[0].head()"
   ],
   "id": "2d1aa98cd45a3768"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "from transformers import pipeline\n",
    "summarizer = pipeline('summarization', model='facebook/bart-large-cnn')\n",
    "summaries = []\n",
    "for df in dfs:\n",
    "    for key, group in df.groupby('cluster'):\n",
    "        text = '\\n'.join(group['title'])[:1024]\n",
    "        summaries.append([key, text, summarizer(text, min_length=10, max_length=50, do_sample=True)[0]['summary_text']])\n",
    "df = pd.DataFrame(summaries, columns=['cluster', 'text', 'summary'])\n",
    "df.to_csv('summaries.csv', index=False)"
   ],
   "id": "c5ee011a2e1d904"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T20:08:05.256128Z",
     "start_time": "2024-04-23T20:08:05.247457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('summaries.csv')\n",
    "df.head()"
   ],
   "id": "b416b6bb11af7887",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T20:08:05.781258Z",
     "start_time": "2024-04-23T20:08:05.256128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "train_test_split = dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = train_test_split['train']\n",
    "valid_dataset = train_test_split['test']"
   ],
   "id": "77ec3b5dd4bc8d86",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T20:08:08.526945Z",
     "start_time": "2024-04-23T20:08:05.783264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import BartTokenizer\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = examples[\"text\"]\n",
    "    targets = examples[\"summary\"]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    # Prepare labels\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=128, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    model_inputs[\"labels\"] = [label if label != tokenizer.pad_token_id else -100 for label in labels[\"input_ids\"]]\n",
    "    return model_inputs\n",
    "\n",
    "# Apply the preprocessing function\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True, remove_columns=['cluster', 'text', 'summary'])\n",
    "valid_dataset = valid_dataset.map(preprocess_function, batched=True, remove_columns=['cluster', 'text', 'summary'])\n",
    "\n"
   ],
   "id": "9a449e6c7be4da19",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T20:08:08.530741Z",
     "start_time": "2024-04-23T20:08:08.527949Z"
    }
   },
   "cell_type": "code",
   "source": "train_dataset",
   "id": "d26d34bb40b8edee",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T20:08:10.067348Z",
     "start_time": "2024-04-23T20:08:08.531757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import BartForConditionalGeneration\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')"
   ],
   "id": "65f6cc59d62973a3",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T20:08:10.093619Z",
     "start_time": "2024-04-23T20:08:10.067348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "# List available CUDA devices\n",
    "if torch.cuda.is_available():\n",
    "    print(\"List of CUDA devices:\", torch.cuda.device_count())\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n"
   ],
   "id": "61c0e14f73d5e2f3",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T20:08:10.559943Z",
     "start_time": "2024-04-23T20:08:10.093619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=2,  # batch size per device during training\n",
    "    per_device_eval_batch_size=2,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=10,\n",
    "    save_strategy='steps',\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=valid_dataset           # evaluation dataset\n",
    ")"
   ],
   "id": "5230f0be5ac503de",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T20:10:57.312067Z",
     "start_time": "2024-04-23T20:08:10.559943Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "6de482fc71e5318b",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T20:10:58.491751Z",
     "start_time": "2024-04-23T20:10:57.312067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.save_pretrained('./fine_tuned_bart')\n",
    "tokenizer.save_pretrained('./fine_tuned_bart')"
   ],
   "id": "4abd16ac0639b7df",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T20:11:01.758497Z",
     "start_time": "2024-04-23T20:10:58.491751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# evaluate\n",
    "trainer.evaluate()"
   ],
   "id": "96ff529716c56c67",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T20:11:05.009529Z",
     "start_time": "2024-04-23T20:11:01.759502Z"
    }
   },
   "cell_type": "code",
   "source": "results = trainer.evaluate()",
   "id": "e839d3807a2c902b",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T20:11:30.985115Z",
     "start_time": "2024-04-23T20:11:30.981210Z"
    }
   },
   "cell_type": "code",
   "source": "results",
   "id": "f284293e4b41d5e5",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "cbb20e02a178bc0f",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
